{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barca won 2-0 against Chelsea at Camp Nou.', 'Messi scored a brace.', \"Valverde's Barca move on\"]\n"
     ]
    }
   ],
   "source": [
    "text = \"Barca won 2-0 against Chelsea at Camp Nou. Messi scored a brace. Valverde's Barca move on\"\n",
    "sents = sent_tokenize(text)\n",
    "print (sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Barca', 'won', '2-0', 'against', 'Chelsea', 'at', 'Camp', 'Nou', '.'], ['Messi', 'scored', 'a', 'brace', '.'], ['Valverde', \"'s\", 'Barca', 'move', 'on']]\n"
     ]
    }
   ],
   "source": [
    "words = [word_tokenize(sent) for sent in sents]\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Set of Custom Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'all', u'just', u\"don't\", u'being', '-', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'don', '$', u'hadn', u'herself', u'll', u'had', ',', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u\"should've\", u\"haven't\", u'do', u'them', u'his', u'very', u\"you've\", u'they', u'not', u'during', u'now', u'him', u'nor', '`', u\"wasn't\", u'd', u'did', '=', u'didn', '^', u'this', u'she', u'each', u'further', u\"won't\", u'where', u\"mustn't\", u\"isn't\", u'few', u'because', u\"you'd\", u'doing', u'some', u'hasn', u\"hasn't\", u'are', u'our', u'ourselves', u'out', u'what', u'for', u\"needn't\", '+', u'below', '/', u're', u'does', u\"shouldn't\", u'above', u'between', u'mustn', '?', u't', u'be', u'we', u'who', u\"mightn't\", u\"doesn't\", u'were', u'here', u'shouldn', u'hers', '[', u\"aren't\", u'by', '_', u'on', u'about', u'couldn', u'of', u\"wouldn't\", '&', u'against', '|', u's', u'isn', '(', '{', u'or', u'own', '*', u'into', u'yourself', u'down', u\"hadn't\", u'mightn', u\"couldn't\", u'wasn', u'your', u\"you're\", '\"', u'from', u'her', u'their', u'aren', u\"it's\", u'there', u'been', '.', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', '\\\\', u'more', u'himself', u'that', u\"didn't\", u'but', ';', '@', u\"that'll\", u'with', u'than', u'those', u'he', u'me', u'myself', ':', u'ma', u\"weren't\", u'these', u'up', '<', u'will', u'while', u'ain', u'can', u'theirs', '>', u'my', '~', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', '!', u'again', '%', u'no', ')', u'when', u'same', u'how', u'other', u'which', u'you', u\"shan't\", u'shan', u'needn', u'haven', u'after', '#', u'most', u'such', ']', u'why', u'a', u'off', \"'\", u'i', u'm', u'yours', u\"you'll\", u'so', u'y', u\"she's\", u'the', '}', u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "customStopWords = set(stopwords.words('english')+list(punctuation))\n",
    "print (customStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StopWord Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barca', '2-0', 'Chelsea', 'Camp', 'Nou', 'Messi', 'scored', 'brace', 'Valverde', \"'s\", 'Barca', 'move']\n"
     ]
    }
   ],
   "source": [
    "#wordsWithoutStopWords = [word for word in word_tokenize(text) if word not in customStopWords]\n",
    "print (wordsWithoutStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((\"'s\", 'Barca'), 1),\n",
       " (('2-0', 'Chelsea'), 1),\n",
       " (('Barca', '2-0'), 1),\n",
       " (('Barca', 'move'), 1),\n",
       " (('Camp', 'Nou'), 1),\n",
       " (('Chelsea', 'Camp'), 1),\n",
       " (('Messi', 'scored'), 1),\n",
       " (('Nou', 'Messi'), 1),\n",
       " (('Valverde', \"'s\"), 1),\n",
       " (('brace', 'Valverde'), 1),\n",
       " (('scored', 'brace'), 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measure = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(wordsWithoutStopWords)\n",
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barc', 'clos', 'in', 'on', 'the', 'clos', 'mov', 'of', 'arth', 'melo', 'who', 'was', 'clos', 'to', 'chelse']\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Barca closing in on the closed move of Arthur melo who was close to Chelsea\"\n",
    "st = LancasterStemmer()\n",
    "stemmedWords = [st.stem(word) for word in word_tokenize(text2)]\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging the Part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Barca', 'NNP'),\n",
       " ('closing', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('closed', 'JJ'),\n",
       " ('move', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Arthur', 'NNP'),\n",
       " ('melo', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('was', 'VBD'),\n",
       " ('close', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('Chelsea', 'NNP')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('bass.n.01'), u'the lowest part of the musical range')\n",
      "(Synset('bass.n.02'), u'the lowest part in polyphonic music')\n",
      "(Synset('bass.n.03'), u'an adult male singer with the lowest voice')\n",
      "(Synset('sea_bass.n.01'), u'the lean flesh of a saltwater fish of the family Serranidae')\n",
      "(Synset('freshwater_bass.n.01'), u'any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)')\n",
      "(Synset('bass.n.06'), u'the lowest adult male singing voice')\n",
      "(Synset('bass.n.07'), u'the member with the lowest range of a family of musical instruments')\n",
      "(Synset('bass.n.08'), u'nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes')\n",
      "(Synset('bass.s.01'), u'having or denoting a low vocal or instrumental range')\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets('bass'):\n",
    "    print (ss,ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('bass.n.07'), u'the member with the lowest range of a family of musical instruments')\n"
     ]
    }
   ],
   "source": [
    "sense1 = lesk(word_tokenize('Sing in a lower tone, along with the bass'),'bass')\n",
    "print (sense1,sense1.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('sea_bass.n.01'), u'the lean flesh of a saltwater fish of the family Serranidae')\n"
     ]
    }
   ],
   "source": [
    "sense2 = lesk(word_tokenize('This sea water bass was very difficult to catch'), 'bass')\n",
    "print (sense2, sense2.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
